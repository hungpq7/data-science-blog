{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDtVVbFylG3y"
   },
   "source": [
    "**LUYỆN TẬP THỰC HÀNH TENSORFLOW**\n",
    "\n",
    "[DAY 1] BASIC MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T08:18:52.285760Z",
     "iopub.status.busy": "2022-03-06T08:18:52.285292Z",
     "iopub.status.idle": "2022-03-06T08:19:21.206151Z",
     "shell.execute_reply": "2022-03-06T08:19:21.205558Z",
     "shell.execute_reply.started": "2022-03-06T08:18:52.285666Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFheJkvclfwy"
   },
   "source": [
    "## 1. Linear regression\n",
    "\n",
    "Cho 2 mảng xs (biến độc lập) và ys (biến phụ thuộc) như dưới, sử dụng tensorflow hãy xây dựng một mô hình đơn giản thể hiện mối quan hệ của 2 biến này"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T08:19:21.207404Z",
     "iopub.status.busy": "2022-03-06T08:19:21.207195Z",
     "iopub.status.idle": "2022-03-06T08:19:21.211669Z",
     "shell.execute_reply": "2022-03-06T08:19:21.210779Z",
     "shell.execute_reply.started": "2022-03-06T08:19:21.207384Z"
    },
    "id": "1RwrL2LCk6d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T08:26:10.244712Z",
     "iopub.status.busy": "2022-03-06T08:26:10.244453Z",
     "iopub.status.idle": "2022-03-06T08:26:10.255065Z",
     "shell.execute_reply": "2022-03-06T08:26:10.254017Z",
     "shell.execute_reply.started": "2022-03-06T08:26:10.244689Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T08:57:23.726387Z",
     "iopub.status.busy": "2022-03-06T08:57:23.725977Z",
     "iopub.status.idle": "2022-03-06T08:57:26.001395Z",
     "shell.execute_reply": "2022-03-06T08:57:26.000600Z",
     "shell.execute_reply.started": "2022-03-06T08:57:23.726349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03436869],\n",
       "       [ 0.9754254 ],\n",
       "       [ 1.9852195 ],\n",
       "       [ 2.9950137 ],\n",
       "       [ 4.0048075 ],\n",
       "       [ 5.0146017 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = layers.Normalization(input_shape=(1,), axis=None)\n",
    "normalizer.adapt(xs)\n",
    "\n",
    "xs = xs.reshape(-1,1)\n",
    "ys = ys.reshape(-1,1)\n",
    "model1 = keras.Sequential()\n",
    "# model1.add(normalizer)\n",
    "model1.add(layers.Dense(units=1))\n",
    "\n",
    "model1.compile(tf.optimizers.Adam(learning_rate=0.1), loss='mean_absolute_error')\n",
    "\n",
    "model1.fit(xs, ys, validation_split=0.2, epochs=100, verbose=0)\n",
    "model1.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0321691],\n",
       "       [1.019416 ],\n",
       "       [2.0066628],\n",
       "       [2.9939098],\n",
       "       [3.9811568],\n",
       "       [4.968404 ]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = layers.Normalization(input_shape=(1,), axis=None)\n",
    "normalizer.adapt(xs)\n",
    "\n",
    "model1 = keras.Sequential()\n",
    "model1.add(normalizer)\n",
    "model1.add(layers.Dense(units=1))\n",
    "\n",
    "model1.compile(tf.optimizers.Adam(learning_rate=0.1), loss='mean_absolute_error')\n",
    "\n",
    "model1.fit(xs, ys, verbose=0, validation_split=0.2, epochs=100)\n",
    "model1.predict(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fAziWyNl99U"
   },
   "source": [
    "## 2. Fashion MNIST\n",
    "\n",
    "Xây dựng mô hình phân loại với bộ dữ liệu Fashion MNIST. <br>\n",
    "Chú ý: đầu vào ảnh 28x28, đầu ra: 10 nhãn phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T09:16:03.469126Z",
     "iopub.status.busy": "2022-03-06T09:16:03.468759Z",
     "iopub.status.idle": "2022-03-06T09:16:03.875542Z",
     "shell.execute_reply": "2022-03-06T09:16:03.874858Z",
     "shell.execute_reply.started": "2022-03-06T09:16:03.469097Z"
    },
    "id": "FTpirOr4mJQA",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "dataset = fashion_mnist.load_data()\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T09:24:58.279445Z",
     "iopub.status.busy": "2022-03-06T09:24:58.279063Z",
     "iopub.status.idle": "2022-03-06T09:24:58.555222Z",
     "shell.execute_reply": "2022-03-06T09:24:58.554357Z",
     "shell.execute_reply.started": "2022-03-06T09:24:58.279411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xTrain, yTrain), (xTest, yTest) = dataset\n",
    "\n",
    "xTrain = xTrain.reshape((-1,28,28,1))\n",
    "xTest = xTest.reshape((-1,28,28,1))\n",
    "\n",
    "xTrain = xTrain / 255\n",
    "xTest = xTest / 255\n",
    "\n",
    "yTrain = keras.utils.to_categorical(yTrain)\n",
    "yTest = keras.utils.to_categorical(yTest)\n",
    "\n",
    "xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T09:41:57.917231Z",
     "iopub.status.busy": "2022-03-06T09:41:57.915351Z",
     "iopub.status.idle": "2022-03-06T09:41:57.953477Z",
     "shell.execute_reply": "2022-03-06T09:41:57.952458Z",
     "shell.execute_reply.started": "2022-03-06T09:41:57.917118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1352)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1352)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                13530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,642\n",
      "Trainable params: 13,626\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(8,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T09:25:05.642378Z",
     "iopub.status.busy": "2022-03-06T09:25:05.641939Z",
     "iopub.status.idle": "2022-03-06T09:25:23.538276Z",
     "shell.execute_reply": "2022-03-06T09:25:23.537546Z",
     "shell.execute_reply.started": "2022-03-06T09:25:05.642342Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.4837 - accuracy: 0.8287 - val_loss: 0.3517 - val_accuracy: 0.8737\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3584 - accuracy: 0.8726 - val_loss: 0.3320 - val_accuracy: 0.8859\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3498 - accuracy: 0.8807\n",
      "Loss: 0.3498\n",
      "Accuracy: 0.8807\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    layers.Conv2D(filters=8, kernel_size=(3,3), strides=1, activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "adam = tf.optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.9)\n",
    "model2.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model2.fit(xTrain, yTrain, epochs=2, validation_split=0.2)\n",
    "\n",
    "loss, acc = model2.evaluate(xTest, yTest)\n",
    "print('Loss: {:.4f}'.format(loss))\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 37s 24ms/step - loss: 0.4039 - accuracy: 0.8620 - val_loss: 0.3168 - val_accuracy: 0.8886\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 36s 24ms/step - loss: 0.2928 - accuracy: 0.8958 - val_loss: 0.3472 - val_accuracy: 0.8788\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 36s 24ms/step - loss: 0.2648 - accuracy: 0.9068 - val_loss: 0.3191 - val_accuracy: 0.8913\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 37s 25ms/step - loss: 0.2480 - accuracy: 0.9129 - val_loss: 0.3163 - val_accuracy: 0.9035\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 40s 26ms/step - loss: 0.2340 - accuracy: 0.9181 - val_loss: 0.3315 - val_accuracy: 0.8948\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 38s 25ms/step - loss: 0.2220 - accuracy: 0.9220 - val_loss: 0.3602 - val_accuracy: 0.8928\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 35s 23ms/step - loss: 0.2177 - accuracy: 0.9237 - val_loss: 0.3386 - val_accuracy: 0.8997\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 36s 24ms/step - loss: 0.2060 - accuracy: 0.9270 - val_loss: 0.4236 - val_accuracy: 0.8876\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 35s 24ms/step - loss: 0.2020 - accuracy: 0.9289 - val_loss: 0.3807 - val_accuracy: 0.8942\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 36s 24ms/step - loss: 0.1887 - accuracy: 0.9328 - val_loss: 0.3983 - val_accuracy: 0.8999\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4266 - accuracy: 0.8982\n",
      "Loss: 0.4266\n",
      "Accuracy: 0.8982\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, activation='relu', input_shape=(28,28)),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "adam = tf.optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.9)\n",
    "model2.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model2.fit(xTrain, yTrain, epochs=10, validation_split=0.2)\n",
    "\n",
    "loss, acc = model2.evaluate(xTest, yTest)\n",
    "print('Loss: {:.4f}'.format(loss))\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5321 - accuracy: 0.8759\n",
      "Loss: 0.5321\n",
      "Accuracy: 0.8759\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(3,3), strides=1, activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "adam = tf.optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.9)\n",
    "model2.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model2.fit(xTrain, yTrain, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "loss, acc = model2.evaluate(xTest, yTest)\n",
    "print('Loss: {:.4f}'.format(loss))\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 282s 188ms/step - loss: 0.5122 - accuracy: 0.8259 - val_loss: 0.2963 - val_accuracy: 0.8917\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 278s 185ms/step - loss: 0.3169 - accuracy: 0.8922 - val_loss: 0.2408 - val_accuracy: 0.9138\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 275s 183ms/step - loss: 0.2694 - accuracy: 0.9083 - val_loss: 0.2405 - val_accuracy: 0.9142\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 294s 196ms/step - loss: 0.2473 - accuracy: 0.9165 - val_loss: 0.2258 - val_accuracy: 0.9236\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 279s 186ms/step - loss: 0.2259 - accuracy: 0.9245 - val_loss: 0.1896 - val_accuracy: 0.9339\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 282s 188ms/step - loss: 0.2132 - accuracy: 0.9295 - val_loss: 0.1917 - val_accuracy: 0.9327\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 283s 189ms/step - loss: 0.1975 - accuracy: 0.9330 - val_loss: 0.1872 - val_accuracy: 0.9369\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 285s 190ms/step - loss: 0.1865 - accuracy: 0.9376 - val_loss: 0.1777 - val_accuracy: 0.9348\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 282s 188ms/step - loss: 0.1756 - accuracy: 0.9415 - val_loss: 0.1833 - val_accuracy: 0.9347\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 279s 186ms/step - loss: 0.1697 - accuracy: 0.9435 - val_loss: 0.2079 - val_accuracy: 0.9262\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.2295 - accuracy: 0.9212\n",
      "Loss: 0.2295\n",
      "Accuracy: 0.9212\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same', input_shape=(28,28,1)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Dropout(0.25))\n",
    "model2.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(layers.Dropout(0.25))\n",
    "model2.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Dropout(0.25))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(512, activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(128, activation='relu'))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "adam = tf.optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.9)\n",
    "model2.compile(optimizer=adam, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model2.fit(xTrain, yTrain, epochs=10, validation_split=0.2)\n",
    "\n",
    "loss, acc = model2.evaluate(xTest, yTest)\n",
    "print('Loss: {:.4f}'.format(loss))\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF training_Day1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
