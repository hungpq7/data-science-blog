<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Ensemble Learning | Data Science Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Ensemble Learning" />
<meta name="author" content="Quang Hung & Thuy Linh" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A overview of Ensemble Learning methods." />
<meta property="og:description" content="A overview of Ensemble Learning methods." />
<link rel="canonical" href="https://hungpq7.github.io/data-science-blog/machine-learning/ensemble-learning/decision-tree/bagging/boosting/2022/08/24/ensemble-learning.html" />
<meta property="og:url" content="https://hungpq7.github.io/data-science-blog/machine-learning/ensemble-learning/decision-tree/bagging/boosting/2022/08/24/ensemble-learning.html" />
<meta property="og:site_name" content="Data Science Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-24T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Ensemble Learning" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Quang Hung & Thuy Linh"},"dateModified":"2022-08-24T00:00:00-05:00","datePublished":"2022-08-24T00:00:00-05:00","description":"A overview of Ensemble Learning methods.","headline":"Ensemble Learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://hungpq7.github.io/data-science-blog/machine-learning/ensemble-learning/decision-tree/bagging/boosting/2022/08/24/ensemble-learning.html"},"url":"https://hungpq7.github.io/data-science-blog/machine-learning/ensemble-learning/decision-tree/bagging/boosting/2022/08/24/ensemble-learning.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/data-science-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hungpq7.github.io/data-science-blog/feed.xml" title="Data Science Blog" /><link rel="shortcut icon" type="image/x-icon" href="/data-science-blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/data-science-blog/">Data Science Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/data-science-blog/about/">About Me</a><a class="page-link" href="/data-science-blog/search/">Search</a><a class="page-link" href="/data-science-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Ensemble Learning</h1><p class="page-description">A overview of Ensemble Learning methods.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-24T00:00:00-05:00" itemprop="datePublished">
        Aug 24, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Quang Hung & Thuy Linh</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/data-science-blog/categories/#machine-learning">machine-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/data-science-blog/categories/#ensemble-learning">ensemble-learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/data-science-blog/categories/#decision-tree">decision-tree</a>
        &nbsp;
      
        <a class="category-tags-link" href="/data-science-blog/categories/#bagging">bagging</a>
        &nbsp;
      
        <a class="category-tags-link" href="/data-science-blog/categories/#boosting">boosting</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/hungpq7/data-science-blog/tree/master/_notebooks/ensemble-learning.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/data-science-blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/hungpq7/data-science-blog/master?filepath=_notebooks%2Fensemble-learning.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/data-science-blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/hungpq7/data-science-blog/blob/master/_notebooks/ensemble-learning.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/data-science-blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fhungpq7%2Fdata-science-blog%2Fblob%2Fmaster%2F_notebooks%2Fensemble-learning.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/data-science-blog/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#1.-Overview">1. Overview </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Big-picture">Big picture </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#2.-Stacking">2. Stacking </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Voting">Voting </a></li>
<li class="toc-entry toc-h3"><a href="#Stacking">Stacking </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#3.-Bagging">3. Bagging </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Random-Forest">Random Forest </a></li>
<li class="toc-entry toc-h3"><a href="#Extra-Trees">Extra Trees </a></li>
<li class="toc-entry toc-h3"><a href="#Implementation">Implementation </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#4.-Boosting">4. Boosting </a></li>
<li class="toc-entry toc-h2"><a href="#5.-Adaptive-Boosting">5. Adaptive Boosting </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Algorithm">Algorithm </a></li>
<li class="toc-entry toc-h3"><a href="#Implementation">Implementation </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#6.-Gradient-Boosting">6. Gradient Boosting </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Algorithm">Algorithm </a></li>
<li class="toc-entry toc-h3"><a href="#Implementation">Implementation </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/ensemble-learning.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.-Overview">
<a class="anchor" href="#1.-Overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Overview<a class="anchor-link" href="#1.-Overview"> </a>
</h2>
<p>Classical Machine Learning algorithms are usually shown to be poor when handling real-world datasets. Models fit from these algorithms often suffer from two problems: high bias and high variance; such a model is called a <em>weak learner</em>. In this topic, we are going through some elegant techniques that combine multiple weak learners to form a powerful model, which produces an improved overall result. This is referred to generally as <a href="https://en.wikipedia.org/wiki/Ensemble_learning">Ensemble Learning</a>. Enemble Learning methods have proven their effectiveness in many Machine Learing competitions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Big-picture">
<a class="anchor" href="#Big-picture" aria-hidden="true"><span class="octicon octicon-link"></span></a>Big picture<a class="anchor-link" href="#Big-picture"> </a>
</h3>
<ul>
<li>Stacking (Wolpert, 1992)<ul>
<li>Voting</li>
<li>Stacking</li>
<li>Blending</li>
</ul>
</li>
<li>Bagging<ul>
<li>
<strong>RandomForest</strong> (Breiman, 1995)</li>
<li>
<strong>ExtraTrees</strong> (Geurts, 2006)</li>
</ul>
</li>
<li>Boosting<ul>
<li>Adaptive Boosting<ul>
<li>
<strong>AdaBoost</strong> (Freund and Schapire, 1995)</li>
</ul>
</li>
<li>Gradient Boosting<ul>
<li>
<strong>GBDT</strong> (Friedman, 2001)<ul>
<li>
<strong>XGBoost</strong> (Chen and Guestrin, 02/2014)</li>
<li>
<strong>LightGBM</strong> (Guolin, 08/2016)</li>
<li>
<strong>CatBoost</strong> (Yandex, 07/2017)</li>
<li>
<strong>NGBoost</strong> (Duan and Avati, 06/2018)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Stacking">
<a class="anchor" href="#2.-Stacking" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Stacking<a class="anchor-link" href="#2.-Stacking"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Voting">
<a class="anchor" href="#Voting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Voting<a class="anchor-link" href="#Voting"> </a>
</h3>
<p><a href="https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier">Voting</a> (for classification) or <a href="https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor">Averaging</a> (for regression) is the simplest ensembling method. When doing voting for classification, there are two strategies can be applied: marjority voting on predicted results (hard voting) and taking argmax of the weighted average of predicted probabilities (soft voting).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span><span class="p">,</span> <span class="n">VotingRegressor</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'data/breast_cancer.csv'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">'target'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xValid</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yValid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf1</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">clf2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">'liblinear'</span><span class="p">)</span>
<span class="n">clf3</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="n">modelsBase</span> <span class="o">=</span> <span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">]</span>
<span class="n">modelsBaseNamed</span> <span class="o">=</span> <span class="p">[(</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">modelsBase</span><span class="p">]</span>
<span class="n">ensembler</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">modelsBaseNamed</span><span class="p">,</span> <span class="n">voting</span><span class="o">=</span><span class="s1">'soft'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">modelsBase</span> <span class="o">+</span> <span class="p">[</span><span class="n">ensembler</span><span class="p">]:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
    <span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:</span> <span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">]'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC = 0.9464 [SVC]
AUC = 0.9931 [LogisticRegression]
AUC = 0.8512 [DecisionTreeClassifier]
AUC = 0.9851 [VotingClassifier]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Stacking">
<a class="anchor" href="#Stacking" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stacking<a class="anchor-link" href="#Stacking"> </a>
</h3>
<p><a href="https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization">Stacking</a> technique organizes its members into two levels:</p>
<ul>
<li>Level 1, a number of <em>base models</em> is fit to ther dataset. Build a new dataset where the values predicted by base models are input variables while the output variable remains the same.</li>
<li>Level 2, a <em>meta model</em> is train on the new dataset to get final prediction.</li>
</ul>
<p>The idea behind stacking is that each base model has an unique approach, it might discover some parts of the ground truth that other models do hot have. Combining them might utilize the their strengths and thus improve the overall quality. Note that Voting is a special case of Stacking, where the final combiner is a very simple model.</p>
<p>In the implementation of Stacking, the base models are often selected <em>heterogeneously</em>, and the meta model is often a simple Logistic Regression model.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingClassifier</span><span class="p">,</span> <span class="n">StackingRegressor</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'data/breast_cancer.csv'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">'target'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xValid</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yValid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">clf1</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">clf2</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">clf3</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">clf4</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">'liblinear'</span><span class="p">)</span>
<span class="n">clf5</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="n">modelsBase</span> <span class="o">=</span> <span class="p">[</span><span class="n">clf1</span><span class="p">,</span> <span class="n">clf2</span><span class="p">,</span> <span class="n">clf3</span><span class="p">,</span> <span class="n">clf4</span><span class="p">,</span> <span class="n">clf5</span><span class="p">]</span>
<span class="n">modelsBaseNamed</span> <span class="o">=</span> <span class="p">[(</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">modelsBase</span><span class="p">]</span>
<span class="n">modelMeta</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">ensembler</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span><span class="n">modelsBaseNamed</span><span class="p">,</span> <span class="n">modelMeta</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">modelsBase</span> <span class="o">+</span> <span class="p">[</span><span class="n">ensembler</span><span class="p">]:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
    <span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:</span> <span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">]'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC = 0.9568 [KNeighborsClassifier]
AUC = 0.9775 [GaussianNB]
AUC = 0.9464 [SVC]
AUC = 0.9931 [LogisticRegression]
AUC = 0.8442 [DecisionTreeClassifier]
AUC = 0.9891 [StackingClassifier]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-Bagging">
<a class="anchor" href="#3.-Bagging" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Bagging<a class="anchor-link" href="#3.-Bagging"> </a>
</h2>
<p><a href="https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator">Bootstrap Aggregating</a> (Bagging) uses averaging/voting method over a number of <em>homogeneous</em> weak models in order to reduce variance. Specifically, Bagging is divided into two parts: <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrapping</a> and aggregating.</p>
<ul>
<li>Boostrapping: The entire dataset is performed random sampling with replacement on both rows and columns. This outputs a number of bootstraps where each of them is different from the others.</li>
<li>Aggregating: after boostrap samples are generated, they are fit into the weak learners. All the model results will be combined by averaging (for regression) or voting (for classification).</li>
</ul>
<p>A Bagging ensembler operates as a committee that outperforms any individual weak model. This wonderful effect - <em>the wisdom of crowds</em> - can be explained that weak models protect each other from their individual errors. If the members share the same behaviors, they also make the same mistakes. Therefore, the low correlation between weak models is the key. Note that the Bagging method requires the initial sample to be large enough for the bootstrapping step to be statistical significant.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Random-Forest">
<a class="anchor" href="#Random-Forest" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random Forest<a class="anchor-link" href="#Random-Forest"> </a>
</h3>
<p><a href="https://en.wikipedia.org/wiki/Random_forest">Random Forest</a> is the implementation of Bagging method on Decision Trees. It can be easily parallelized, does not requires too much hyperparameters tuning and has a decent prediction power. Random Forest is a very popular algorithm, before Boosting methods take the crown.</p>
<p><code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">RandomForestClassifier</a></code>
and
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">RandomForestRegressor</a></code>
classes have the following Bagging hyperparameters (ones inherited from Decision Tree are not mentioned):</p>
<ul>
<li>
<code style="font-size:13px; color:#BA2121">n_estimators</code>: the number of trees in the forest, defaults to <em>100</em>. Control the complexity of the algorithm. Try increasing this when the model is underfitting, but it will take a longer training time.</li>
<li>
<code style="font-size:13px; color:#BA2121">max_features</code>: the ratio of features used in each tree, defaults to <em>auto</em> (square root of <em>nFeature</em>). A lower value increases bias and reduces variance.</li>
<li>
<code style="font-size:13px; color:#BA2121">max_samples</code>: the ratio of instances used in each tree, defaults to <em>None</em> (100% of <em>nSample</em>). A lower value increases bias and reduces variance.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Extra-Trees">
<a class="anchor" href="#Extra-Trees" aria-hidden="true"><span class="octicon octicon-link"></span></a>Extra Trees<a class="anchor-link" href="#Extra-Trees"> </a>
</h3>
<p>Besides Random Forest, Sickit-learn also develops a quite similar algorithm, Extremely Randomized Trees (Extra Trees for short). Instead of finding the split with highest information gain at each step, this method goes one step further in randomness by selecting the best candidate among a number of randomly-generated cut points.</p>
<p>The 
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html">ExtraTreesClassifier</a></code>
and
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html">ExtraTreesRegressor</a></code>
classes have same hyperparameters as in Random Forest, there are only some small differences in their default values.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation">
<a class="anchor" href="#Implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation<a class="anchor-link" href="#Implementation"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span><span class="p">,</span> <span class="n">BaggingRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span><span class="p">,</span> <span class="n">ExtraTreesRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'data/breast_cancer.csv'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">'target'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xValid</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yValid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelBase</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">'liblinear'</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="mi">10</span><span class="p">})</span>
<span class="n">ensembler</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">modelBase</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">model1</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">modelBase</span><span class="p">,</span> <span class="n">ensembler</span><span class="p">,</span> <span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">]</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
    <span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:</span> <span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">]'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC = 0.9845 [LogisticRegression]
AUC = 0.9897 [BaggingClassifier]
AUC = 0.9688 [RandomForestClassifier]
AUC = 0.9749 [ExtraTreesClassifier]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Boosting">
<a class="anchor" href="#4.-Boosting" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Boosting<a class="anchor-link" href="#4.-Boosting"> </a>
</h2>
<p><a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)">Boosting</a> works in the same spirit as Bagging: it also build a group of <em>homogeneous</em> models to obtain a more powerful predictor. The difference is that Boosting trains weak models sequentially while Bagging perform the training independently. The idea behind Boosting is to fit models iteratively such that the training of each model depends on the previous ones. Using this strategy, badly handled observations in the earlier steps will be taken care better in the later steps. Since the Boosting method puts its efforts on important cases, we end up have a strong learner with lower bias.</p>
<p>In many competitions, Boosting methods used on Decision Trees are so effective for tabular datasets and is widely used by top competitors. For the rest of this article, we will take a deep dive into a bunch of interesting Boosting algorithms. To start off, let's take a quick overview of two Boosting approaches, Adaptive Boosting and Gradient Boosting. They do both train trees consequently, but behave differently. We first denote: $\eta$ - the learning rate, $T$ - the number of iterations, $f^{(t)}$ and $f^{(t)}(\mathbf{X})$ - the tree number $t$ and its predicted value for $t=1,2,\dots,T$.</p>
<p><em>Adaptive Boosting</em></p>
<ul>
<li>Train $f^{(1)}$</li>
<li>Train $f^{(2)}$ base on $f^{(1)}$</li>
<li>Train $f^{(3)}$ base on $f^{(2)}$</li>
<li>...</li>
<li>Train $f^{(T)}$ base on $f^{(T-1)}$</li>
<li>Scale each tree by a coefficient $\eta$ and predict
$\hat{\mathbf{y}}\leftarrow\eta f^{(1)}(\mathbf{X})+\eta f^{(2)}(\mathbf{X})+\dots+\eta f^{(T)}(\mathbf{X})$</li>
</ul>
<p><em>Gradient Boosting</em></p>
<ul>
<li>Intialize $\hat{\mathbf{y}}^{(0)}$</li>
<li>Train $f^{(1)}$ base on $\hat{\mathbf{y}}^{(0)}$ and compute $\hat{\mathbf{y}}^{(1)}=\hat{\mathbf{y}}^{(0)}+\eta f^{(1)}(\mathbf{X})$</li>
<li>Train $f^{(2)}$ base on $\hat{\mathbf{y}}^{(1)}$ and compute $\hat{\mathbf{y}}^{(2)}=\hat{\mathbf{y}}^{(1)}+\eta f^{(2)}(\mathbf{X})$</li>
<li>...</li>
<li>Train $f^{(T)}$ base on $\hat{\mathbf{y}}^{(T-1)}$ and compute $\hat{\mathbf{y}}^{(T)}=\hat{\mathbf{y}}^{(T-1)}+\eta f^{(T)}(\mathbf{X})$</li>
<li>Predict $\hat{\mathbf{y}}\leftarrow\hat{\mathbf{y}}^{(T)}$</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="5.-Adaptive-Boosting">
<a class="anchor" href="#5.-Adaptive-Boosting" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Adaptive Boosting<a class="anchor-link" href="#5.-Adaptive-Boosting"> </a>
</h2>
<p><a href="https://en.wikipedia.org/wiki/AdaBoost">Adaptive Boosting</a> was originally designed for binary classification problems. This method can be used to boost any algorithm, but Decision Tree is always the go-to choice. More specifically, Decision Trees used here are very shallow, they only have one root and two leaves, explaining why they are also called Decision Stumps.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Algorithm">
<a class="anchor" href="#Algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Algorithm<a class="anchor-link" href="#Algorithm"> </a>
</h3>
<p><em>Input:</em></p>
<ul>
<li>A dataset having $N$ observations $(\mathbf{X},\mathbf{y})=\{(\mathbf{s}_n,y_n)\}_{n=1}^N$ where $y_n\in\{-1,1\}$</li>
<li>The number of weak models, $T$</li>
<li>The learning rate, $\eta$</li>
</ul>
<p><em>Step 1.</em> Initialize the weight for each observation: $w_n^{(1)}=1/N$.</p>
<p><em>Step 2.</em> For each iteration number $t$ where $t=1,2,\dots,T$:</p>
<ul>
<li>
<p>Train a weak model $f^{(t)}$ that minimizes the sum of weights over misclassifications, represented by the error:</p>
<p>$$\epsilon^{(t)}=\sum_{n=1}^{N}{w_n^{(t)}\left[\hat{y}_n\neq y_n\right]}$$</p>
</li>
<li>
<p>Calculate $\alpha^{(t)}$ the amount of say for the current weak classifier; deciding how much $f^{(t)}$ will contribute in the final prediction. This calculation rewards $f^{(t)}$ a very high influence if its total error is low and penalizes $f^{(t)}$ a negative influence for a high total error.</p>
<p>$$\alpha^{(t)}=\frac{\eta}{2}\,\log{\frac{1-\epsilon^{(t)}}{\epsilon^{(t)}}}$$</p>
</li>
<li>
<p>Update sample weights for the next iteration so that: the weights of the correctly classied samples decrease $\exp{(\alpha^{(t)})}$ times and the weights of misclassifications increase the same amount. Notice that the term $-\hat{y}_n y_n$ equals to $1$ if the prediction is correct and equals to $-1$ if the prediction is incorrect.</p>
<p>$$w_n^{(t+1)}=w_n^{(t)}\exp{\left(-\hat{y}_n y_n\alpha^{(t)}\right)}$$</p>
</li>
<li>
<p>Normalize new weights so that they add up to $1$. This step is required to make the calculation of $\alpha^{(t+1)}$ meaningful. At this step, some implementations resample the dataset so that the distribution of observations follows the newly calculated weights.</p>
</li>
</ul>
<p><em>Step 3.</em> Build an additive strong model that performs weighted voting over $T$ weak learners; this is model outputs the prediction of the algorithm, $\hat{\mathbf{y}}$. The formula uses the notation $\text{sign}(\bullet)$, indicating the <a href="https://en.wikipedia.org/wiki/Sign_function">sign function</a>.</p>
<p>
$$\hat{\mathbf{y}}=\text{sign}\left(\sum_{t=1}^T\alpha^{(t)} f^{(t)}(\mathbf{X})\right)$$
</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">([</span><span class="s1">'seaborn'</span><span class="p">,</span> <span class="s1">'seaborn-whitegrid'</span><span class="p">])</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">eta</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">*</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">'k'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">fr</span><span class="s1">'Learning rate = </span><span class="si">{</span><span class="n">eta</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'scaled'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'Error, $\epsilon_t$'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">'Influence, $\alpha_t$'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A" width="335" height="308">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation">
<a class="anchor" href="#Implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation<a class="anchor-link" href="#Implementation"> </a>
</h3>
<p>The classes
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html">AdaBoostClassifier</a></code>
and
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html">AdaBoostRegressor</a></code>
have the following Boosting hyperparameters:</p>
<ul>
<li>
<code style="font-size:13px; color:#BA2121">base_estimator</code>: the algorithm to be boosted, defaults to <em>None</em> (Decision Tree with max depth of 1).</li>
<li>
<code style="font-size:13px; color:#BA2121">n_estimators</code>: the number of boosting stages ($T$), defaults to <em>50</em>.</li>
<li>
<code style="font-size:13px; color:#BA2121">learning_rate</code>: the learning rate ($\eta$), defaults to <em>1</em>.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">AdaBoostRegressor</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'data/breast_cancer.csv'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">'target'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xValid</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yValid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">modelBase</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ensembler</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">modelBase</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">ensembler</span><span class="p">]</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
    <span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:</span> <span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">]'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC = 0.9828 [AdaBoostClassifier]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="6.-Gradient-Boosting">
<a class="anchor" href="#6.-Gradient-Boosting" aria-hidden="true"><span class="octicon octicon-link"></span></a>6. Gradient Boosting<a class="anchor-link" href="#6.-Gradient-Boosting"> </a>
</h2>
<p><a href="https://en.wikipedia.org/wiki/Gradient_boosting">Grandient Boosting</a> is another boosting strategy beside Adaptive Boosting. The idea of this method is mostly inspired by <a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent</a>, thus the name Gradient Boosting. Just like other ensembling methods, this algorithm works best on Decision Trees and becomes the foundation for its modern variants such as XGBoost, LightGBM and CatBoost.</p>
<p>Gradient Boosting Trees was originally designed for regression problems. For classification, we use regression approach to predict <a href="https://en.wikipedia.org/wiki/Logit">log of the odds</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Algorithm">
<a class="anchor" href="#Algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Algorithm<a class="anchor-link" href="#Algorithm"> </a>
</h3>
<p><em>Input:</em></p>
<ul>
<li>A dataset having $N$ labeled observations $(\mathbf{X},\mathbf{y})=\{(\mathbf{s}_n,y_n)\}_{n=1}^N$</li>
<li>The number of weak models, $T$</li>
<li>The learning rate, $\eta$</li>
<li>A <a href="https://en.wikipedia.org/wiki/Differentiable_function">differentiable</a> loss function $\mathcal{L}(\hat{\mathbf{y}})$ (<a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares">squared error</a> is a popular choice)</li>
</ul>
<p><em>Step 1.</em> Initialize the prediction as a constant. Since this is the very first prediction and will be updated step-by-step, we denote this value $\hat{\mathbf{y}}^{(0)}$. When the loss function is MSE, this value is nothing but the mean of $\mathbf{y}$.</p>
<p>
$$\hat{\mathbf{y}}^{(0)}=\arg\min\sum_{n=1}^N \mathcal{L}(\hat{y}_n)$$
</p>
<p><em>Step 2.</em> For $t=1$ to $T$:</p>
<ul>
<li>
<p>Compute the psuedo-residual $r_n^{(t)}$ equals to the negative gradient of the loss function with respect to the prediction of the iteration $t-1$. When MSE is used, this term is proportional to the actual residual, $y_n-\hat{y}_n^{(t-1)}$. In general, we call it pseudo-residual which allows plugging in different loss functions.</p>
<p>$$r_n^{(t)}=-g_n^{(t)}=-\frac{\partial\mathcal{L}(\hat{y}_n^{(t-1)})}{\partial \hat{y}_n^{(t-1)}}$$</p>
</li>
<li>
<p>Fit a weak learner (regression tree) $f^{(t)}$ using the training set $(\mathbf{X},\mathbf{r}^{(t)})$. This step results in a tree with $M$ leaf nodes; meaning the input space is split into $M$ <a href="https://en.wikipedia.org/wiki/Disjoint_sets">disjoint</a> regions, each region is denoted $R_m\;(m=1,2,\dots,M)$. Trees in this step are not restricted to be stumps as in AdaBoost. Compute $f^{(t)}(\mathbf{X})$, the predicted value for the model $f^{(t)}$ so that it minimizes the loss function at the current step.</p>
<p>$$f^{(t)}(\mathbf{X})=\underset{f}{\arg\min}\sum_{n=1}^{N}{\mathcal{L}\left(\hat{y}_n^{(t-1)}+f(\mathbf{s}_n)\right)}$$</p>
</li>
<li>
<p>Use first-order <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor approximation</a>: $f(x=a)\approx f(a)+f'(a)(x-a)$ to estimate the loss function evaluated at step $t-1$. Here, $x$ corresponds to $\hat{y}_n^{(t-1)}+f(\mathbf{s}_n)$ and $a$ corresponds to $\hat{y}_n^{(t-1)}$. Using the notation $g_n^{(t)}$ defined earlier, we have:
$\mathcal{L}\left(\hat{y}_n^{(t-1)}+f(\mathbf{s}_n)\right)\approx\mathcal{L}\left(\hat{y}_n^{(t-1)}\right)+g_n^{(t)}f(\mathbf{s}_n)$.
We can prove that $f^{(t)}(\mathbf{X})$ is proportional to the negative gradient as follows. When MSE is chosen, is simply computes the average residual in each leaf.</p>
<p>$$\begin{align*}
f^{(t)}(\mathbf{X})
&amp;\approx \underset{f}{\arg\min} \sum_{n=1}^{N}\mathcal{L}\left(\hat{y}_n^{(t-1)}\right)+g_n^{(t)}f(\mathbf{s}_n) \\
&amp;= \underset{f}{\arg\min} \sum_{n=1}^{N}g_n^{(t)}f(\mathbf{s}_n) \propto -g_n^{(t)}
\end{align*}$$</p>
</li>
<li>
<p>Compute the predicted value up to the current step, $\hat{\mathbf{y}}^{(t)}$. Since we are adding negative gradient $-g_n^{(t-1)}$ scaled by the learning rate $\eta$ step-by-step, this can be considered a Gradient Descent process.</p>
<p>$$\hat{\mathbf{y}}^{(t)}=\hat{\mathbf{y}}^{(t-1)}+\eta f^{(t)}(\mathbf{X})$$</p>
</li>
</ul>
<p><em>Step 3</em>. Take the last round's predicted value as the final prediction: $\hat{\mathbf{y}}\leftarrow \hat{\mathbf{y}}^{(T)}$. Note that in Gradient Boosting, the prediction at each iteration $\hat{\mathbf{y}}^{(t)}$ has taken into account all weak learners up to the current step. This behaviour is not like Adaptive Boosting, in which the strong model is only built once all weak leaners was trained successfully.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation">
<a class="anchor" href="#Implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation<a class="anchor-link" href="#Implementation"> </a>
</h3>
<p>The
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html">GradientBoostingClassifier</a></code>
and
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html">GradientBoostingRegressor</a></code>
classes are the original impelementation of Gradient Boosting Trees. After a while,
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html">HistGradientBoostingClassifier</a></code>
and
<code style="font-size:13px"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html">HistGradientBoostingRegressor</a></code>
which use histogram-based split finding were introduced. The later implementation is significantly faster for big datasets. The common hyperparameters of these algorithms are:</p>
<ul>
<li>
<code style="font-size:13px; color:#BA2121">loss</code>: the type of loss function, defaults to <em>deviance</em> (classification) and <em>squared_error</em> (regression).</li>
<li>
<code style="font-size:13px; color:#BA2121">n_estimators</code>: the number of boosting stages ($T$), defaults to <em>100</em>.</li>
<li>
<code style="font-size:13px; color:#BA2121">learning_rate</code>: the learning rate ($\eta$), defaults to <em>0.1</em>.</li>
<li>
<code style="font-size:13px; color:#BA2121">max_features</code>: the ratio of features used in each tree, defaults to <em>auto</em> (square root of <em>nFeature</em>). A lower value increases bias and reduces variance.</li>
<li>
<code style="font-size:13px; color:#BA2121">subsample</code>: the ratio of instances used in each tree, defaults to <em>1</em> (100% of <em>nSample</em>). A lower value increases bias and reduces variance.</li>
<li>
<code style="font-size:13px; color:#BA2121">criterion</code>: the measure of quality of splits, defaults to <em>friedman_mse</em>.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">HistGradientBoostingClassifier</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dfCancer</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'data/breast_cancer.csv'</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">'target'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dfCancer</span><span class="o">.</span><span class="n">target</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xTest</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yTest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xTrain</span><span class="p">,</span> <span class="n">xValid</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">yValid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model1</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xTrain</span><span class="p">,</span> <span class="n">yTrain</span><span class="p">)</span>
    <span class="n">yPred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">xTest</span><span class="p">)[:</span> <span class="p">,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">yTest</span><span class="p">,</span> <span class="n">yPred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1"> [</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">]'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>AUC = 0.9729 [GradientBoostingClassifier]
AUC = 0.9831 [HistGradientBoostingClassifier]
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="hungpq7/data-science-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/data-science-blog/machine-learning/ensemble-learning/decision-tree/bagging/boosting/2022/08/24/ensemble-learning.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/data-science-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/data-science-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/data-science-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/data-science-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/data-science-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
